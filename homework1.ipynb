{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1 Helloworld","metadata":{}},{"cell_type":"code","source":"%%writefile hello.cu\n#include <stdio.h>\n\n__global__ void hello(){\n\n  printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n}\n\nint main(){\n\n  hello<<<2,2>>>();\n  cudaDeviceSynchronize();\n}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-29T17:58:31.665565Z","iopub.execute_input":"2024-06-29T17:58:31.665952Z","iopub.status.idle":"2024-06-29T17:58:31.671759Z","shell.execute_reply.started":"2024-06-29T17:58:31.665925Z","shell.execute_reply":"2024-06-29T17:58:31.670799Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Overwriting hello.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"%%script bash\nnvcc ./hello.cu -o hello_cuda \n./hello_cuda ","metadata":{"execution":{"iopub.status.busy":"2024-06-29T17:58:31.673421Z","iopub.execute_input":"2024-06-29T17:58:31.673714Z","iopub.status.idle":"2024-06-29T17:58:32.681904Z","shell.execute_reply.started":"2024-06-29T17:58:31.673675Z","shell.execute_reply":"2024-06-29T17:58:32.680950Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Hello from block: 0, thread: 0\nHello from block: 0, thread: 1\nHello from block: 1, thread: 0\nHello from block: 1, thread: 1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2 Vector Add","metadata":{}},{"cell_type":"code","source":"%%writefile vector_add.cu\n#include <stdio.h>\n\n// error checking macro\n#define cudaCheckErrors(msg) \\\n    do { \\\n        cudaError_t __err = cudaGetLastError(); \\\n        if (__err != cudaSuccess) { \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n                msg, cudaGetErrorString(__err), \\\n                __FILE__, __LINE__); \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n            exit(1); \\\n        } \\\n    } while (0)\n\n\nconst int DSIZE = 4096;\nconst int block_size = 256;  // CUDA maximum is 1024\n// vector add kernel: C = A + B\n__global__ void vadd(const float *A, const float *B, float *C, int ds){\n\n  int idx = threadIdx.x + blockIdx.x * ds; // create typical 1D thread index from built-in variables\n  if (idx < ds){\n    C[idx] = A[idx] + B[idx];         // do the vector (element) add here\n  }\n}\n\nint main(){\n\n  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n  h_A = new float[DSIZE];  // allocate space for vectors in host memory\n  h_B = new float[DSIZE];\n  h_C = new float[DSIZE];\n  for (int i = 0; i < DSIZE; i++){  // initialize vectors in host memory\n    h_A[i] = rand()/(float)RAND_MAX;\n    h_B[i] = rand()/(float)RAND_MAX;\n    h_C[i] = 0;}\n  cudaMalloc(&d_A, DSIZE*sizeof(float));  // allocate device space for vector A\n  cudaMalloc(&d_B, DSIZE*sizeof(float)); // allocate device space for vector B\n  cudaMalloc(&d_C, DSIZE*sizeof(float)); // allocate device space for vector C\n  cudaCheckErrors(\"cudaMalloc failure\"); // error checking\n  // copy vector A to device:\n  cudaMemcpy(d_A, h_A, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n  // copy vector B to device:\n  cudaMemcpy(d_B, h_B, DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n  //cuda processing sequence step 1 is complete\n  vadd<<<(DSIZE+block_size-1)/block_size, block_size>>>(d_A, d_B, d_C, DSIZE);\n  cudaCheckErrors(\"kernel launch failure\");\n  //cuda processing sequence step 2 is complete\n  // copy vector C from device to host:\n  cudaMemcpy(h_C, d_C, DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n  //cuda processing sequence step 3 is complete\n  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n  printf(\"A[0] = %f\\n\", h_A[0]);\n  printf(\"B[0] = %f\\n\", h_B[0]);\n  printf(\"C[0] = %f\\n\", h_C[0]);\n  return 0;\n}\n  ","metadata":{"execution":{"iopub.status.busy":"2024-06-29T17:58:32.683363Z","iopub.execute_input":"2024-06-29T17:58:32.683647Z","iopub.status.idle":"2024-06-29T17:58:32.690647Z","shell.execute_reply.started":"2024-06-29T17:58:32.683623Z","shell.execute_reply":"2024-06-29T17:58:32.689827Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Overwriting vector_add.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"%%script bash\nnvcc ./vector_add.cu -o vector_add\n./vector_add","metadata":{"execution":{"iopub.status.busy":"2024-06-29T17:58:32.692289Z","iopub.execute_input":"2024-06-29T17:58:32.692564Z","iopub.status.idle":"2024-06-29T17:58:33.640554Z","shell.execute_reply.started":"2024-06-29T17:58:32.692541Z","shell.execute_reply":"2024-06-29T17:58:33.639833Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"A[0] = 0.840188\nB[0] = 0.394383\nC[0] = 1.234571\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3 Matrix Multiply (naive)","metadata":{}},{"cell_type":"code","source":"%%writefile matrix_multiply.cu\n#include <stdio.h>\n\n// these are just for timing measurments\n#include <time.h>\n\n// error checking macro\n#define cudaCheckErrors(msg) \\\n    do { \\\n        cudaError_t __err = cudaGetLastError(); \\\n        if (__err != cudaSuccess) { \\\n            fprintf(stderr, \"Fatal error: %s (%s at %s:%d)\\n\", \\\n                msg, cudaGetErrorString(__err), \\\n                __FILE__, __LINE__); \\\n            fprintf(stderr, \"*** FAILED - ABORTING\\n\"); \\\n            exit(1); \\\n        } \\\n    } while (0)\n\n\nconst int DSIZE = 4096;\nconst int block_size = 16;  // CUDA maximum is 1024 *total* threads in block\nconst float A_val = 1.0f;\nconst float B_val = 2.0f;\n\n// matrix multiply (naive) kernel: C = A * B\n__global__ void mmul(const float *A, const float *B, float *C, int ds) {\n\n  int idx = threadIdx.x+blockDim.x*blockIdx.x; // create thread x index\n  int idy = threadIdx.y+blockDim.y*blockIdx.y; // create thread y index\n\n  if ((idx < ds) && (idy < ds)){\n    float temp = 0;\n    for (int i = 0; i < ds; i++)\n      temp += A[idy*ds+i] * B[i*ds+idx];   // dot product of row and column\n    C[idy*ds+idx] = temp;\n  }\n}\n\nint main(){\n\n  float *h_A, *h_B, *h_C, *d_A, *d_B, *d_C;\n\n  // these are just for timing\n  clock_t t0, t1, t2;\n  double t1sum=0.0;\n  double t2sum=0.0;\n\n  // start timing\n  t0 = clock();\n\n  h_A = new float[DSIZE*DSIZE];\n  h_B = new float[DSIZE*DSIZE];\n  h_C = new float[DSIZE*DSIZE];\n  for (int i = 0; i < DSIZE*DSIZE; i++){\n    h_A[i] = A_val;\n    h_B[i] = B_val;\n    h_C[i] = 0;}\n\n  // Initialization timing\n  t1 = clock();\n  t1sum = ((double)(t1-t0))/CLOCKS_PER_SEC;\n  printf(\"Init took %f seconds.  Begin compute\\n\", t1sum);\n\n  // Allocate device memory and copy input data over to GPU\n  cudaMalloc(&d_A, DSIZE*DSIZE*sizeof(float));\n  cudaMalloc(&d_B, DSIZE*DSIZE*sizeof(float));\n  cudaMalloc(&d_C, DSIZE*DSIZE*sizeof(float));\n  cudaCheckErrors(\"cudaMalloc failure\");\n  cudaMemcpy(d_A, h_A, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n  cudaMemcpy(d_B, h_B, DSIZE*DSIZE*sizeof(float), cudaMemcpyHostToDevice);\n  cudaCheckErrors(\"cudaMemcpy H2D failure\");\n\n  // Cuda processing sequence step 1 is complete\n\n  // Launch kernel\n  dim3 block(block_size, block_size);  // dim3 variable holds 3 dimensions\n  dim3 grid((DSIZE+block.x-1)/block.x, (DSIZE+block.y-1)/block.y);\n  mmul<<<grid, block>>>(d_A, d_B, d_C, DSIZE);\n  cudaCheckErrors(\"kernel launch failure\");\n\n  // Cuda processing sequence step 2 is complete\n\n  // Copy results back to host\n  cudaMemcpy(h_C, d_C, DSIZE*DSIZE*sizeof(float), cudaMemcpyDeviceToHost);\n\n  // GPU timing\n  t2 = clock();\n  t2sum = ((double)(t2-t1))/CLOCKS_PER_SEC;\n  printf (\"Done. Compute took %f seconds\\n\", t2sum);\n\n  // Cuda processing sequence step 3 is complete\n\n  // Verify results\n  cudaCheckErrors(\"kernel execution failure or cudaMemcpy H2D failure\");\n  for (int i = 0; i < DSIZE*DSIZE; i++) if (h_C[i] != A_val*B_val*DSIZE) {printf(\"mismatch at index %d, was: %f, should be: %f\\n\", i, h_C[i], A_val*B_val*DSIZE); return -1;}\n  printf(\"Success!\\n\"); \n\n  return 0;\n}\n  ","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:05:50.935294Z","iopub.execute_input":"2024-06-29T18:05:50.935949Z","iopub.status.idle":"2024-06-29T18:05:50.943379Z","shell.execute_reply.started":"2024-06-29T18:05:50.935921Z","shell.execute_reply":"2024-06-29T18:05:50.942450Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Writing matrix_multiply.cu\n","output_type":"stream"}]},{"cell_type":"code","source":"%%script bash\nnvcc ./matrix_multiply.cu -o matrix_multiply\n./matrix_multiply","metadata":{"execution":{"iopub.status.busy":"2024-06-29T18:05:55.364900Z","iopub.execute_input":"2024-06-29T18:05:55.365768Z","iopub.status.idle":"2024-06-29T18:05:57.837769Z","shell.execute_reply.started":"2024-06-29T18:05:55.365735Z","shell.execute_reply":"2024-06-29T18:05:57.837023Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Init took 0.295455 seconds.  Begin compute\nDone. Compute took 1.236125 seconds\nSuccess!\n","output_type":"stream"}]}]}